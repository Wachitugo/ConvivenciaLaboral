import asyncio
import logging
from typing import Dict, List, Optional
from langchain_google_vertexai import ChatVertexAI
from langchain_core.messages import SystemMessage, HumanMessage
from app.core.config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


class IntentRouter:
    """
    Routes user requests to optimal execution paths based on intent classification.
    Reduces unnecessary tool calls and ReAct loops for common query types.
    """
    
    # Intent types
    DOCUMENT_ANALYSIS = "DOCUMENT_ANALYSIS"
    SIMPLE_QA = "SIMPLE_QA"
    TOOL_REQUIRED = "TOOL_REQUIRED"
    CASE_QUERY = "CASE_QUERY"
    CASE_CREATION = "CASE_CREATION"
    
    def __init__(self):
        self._llm = None
        self.model_location = settings.VERTEX_LOCATION or "us-central1"
        self._cache = {}  # Simple cache for intent classification
    
    @property
    def llm(self):
        """Lazy-loaded LLM for intent classification"""
        if self._llm is None:
            model_name = settings.VERTEX_MODEL_FLASH or settings.VERTEX_MODEL or "gemini-2.0-flash-exp"
            logger.info(f"ğŸ¤– [INTENT] Initializing LLM with model: {model_name}")
            self._llm = ChatVertexAI(
                model_name=model_name,
                temperature=0.1,  # Low temperature for consistent classification
                max_output_tokens=512,  # Enough for structured output
                project=settings.PROJECT_ID,
                location=self.model_location,
            )
        return self._llm
    
    async def classify_intent(
        self,
        message: str,
        has_files: bool = False,
        case_id: Optional[str] = None,
        history: List = None,
        user_id: Optional[str] = None
    ) -> Dict[str, any]:
        """
        Classifies user intent using FAST-PATHS for obvious cases and LLM for ambiguous ones.
        
        Architecture:
        1. Fast-path heuristics (~20 lines) for 100% obvious cases
        2. LLM classification for everything else (robust, handles edge cases)
        
        Args:
            message: User message
            has_files: Whether files are attached
            case_id: Active case ID if applicable
            history: Conversation history
            user_id: User ID for token tracking
            
        Returns:
            {
                "intent": str,  # Intent type
                "confidence": float,  # 0.0 to 1.0
                "reasoning": str  # Why this intent was chosen
            }
        """
        try:
            import re
            message_lower = message.lower()
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # FAST-PATH #1: Email address detected â†’ TOOL_REQUIRED
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
            if re.search(email_pattern, message):
                logger.info(f"ğŸ¯ [INTENT] Fast-path: TOOL_REQUIRED (email address detected)")
                return {
                    "intent": self.TOOL_REQUIRED,
                    "confidence": 0.98,
                    "reasoning": "Email address detected in message"
                }
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # FAST-PATH #2: Explicit tool requests (email/calendar phrases)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            tool_phrases = [
                "enviar correo", "redactar correo", "enviar email", "redactar email",
                "enviar mail", "agendar reuniÃ³n", "agendar reunion", "agenda cita",
                "programar cita", "preparar correo", "notificar por correo",
                "agendar citaciÃ³n", "citar a declarar", "enviar notificaciÃ³n"
            ]
            
            if any(phrase in message_lower for phrase in tool_phrases):
                logger.info(f"ğŸ¯ [INTENT] Fast-path: TOOL_REQUIRED (explicit tool phrase)")
                return {
                    "intent": self.TOOL_REQUIRED,
                    "confidence": 0.95,
                    "reasoning": "Explicit tool request phrase detected"
                }
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # FAST-PATH #3: Active case conversation continuation
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if history and len(history) >= 2 and not case_id:
                recent = history[-6:] if len(history) > 6 else history
                recent_text = " ".join([
                    m.content.lower() for m in recent 
                    if hasattr(m, 'content') and isinstance(m.content, str)
                ])
                
                # Indicadores de caso activo (Laboral)
                case_indicators = [
                    "tengo una denuncia", "trabajador", "denunciado", "denunciante",
                    "testigos", "fecha del incidente", "acoso laboral", "acoso sexual",
                    "violencia", "hostigamiento", "jefe", "supervisor"
                ]
                
                if any(indicator in recent_text for indicator in case_indicators):
                    logger.info("ğŸ¯ [INTENT] Fast-path: CASE_CREATION (active conversation)")
                    return {
                        "intent": self.CASE_CREATION,
                        "confidence": 0.90,
                        "reasoning": "Active case documentation conversation in history"
                    }
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # FAST-PATH #4: Files attached + analysis verbs â†’ DOCUMENT_ANALYSIS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if has_files:
                analysis_verbs = ["analiz", "revis", "examin", "lee", "resum", "que dice", "que contiene"]
                file_refs = ["archivo", "documento", "adjunto", "pdf", "contrato", "carta"]
                
                has_analysis = any(verb in message_lower for verb in analysis_verbs)
                has_file_ref = any(ref in message_lower for ref in file_refs)
                is_short_question = "?" in message and len(message.split()) < 10
                
                if has_analysis or has_file_ref or is_short_question:
                    logger.info("ğŸ¯ [INTENT] Fast-path: DOCUMENT_ANALYSIS (files + query)")
                    return {
                        "intent": self.DOCUMENT_ANALYSIS,
                        "confidence": 0.95,
                        "reasoning": "Files attached with analysis request"
                    }
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # LLM CLASSIFICATION: For all ambiguous cases
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info("ğŸ§  [INTENT] Using LLM for classification (no fast-path matched)")
            return await self._llm_classify(message, has_files, case_id, user_id)
            
        except Exception as e:
            logger.warning(f"âš ï¸ [INTENT] Classification error: {e}")
            return {
                "intent": self.TOOL_REQUIRED,
                "confidence": 0.5,
                "reasoning": f"Error during classification: {e}"
            }
    
    def _is_case_query(self, message: str) -> bool:
        """Fast keyword detection for case queries (deprecated - now using LLM)"""
        query_keywords = [
            "de que trata", "que caso", "cual es el caso", "resumen del caso",
            "quien esta involucrado", "archivos del caso", "detalles del caso"
        ]
        message_lower = message.lower()
        return any(k in message_lower for k in query_keywords)
    
    async def _llm_classify(self, message: str, has_files: bool, case_id: Optional[str], user_id: Optional[str] = None) -> Dict:
        """Use LLM to classify when heuristics are insufficient"""
        from pydantic import BaseModel, Field
        from datetime import datetime
        from app.services.users.user_service import user_service
        
        class IntentClassification(BaseModel):
            intent: str = Field(description="DOCUMENT_ANALYSIS, SIMPLE_QA, TOOL_REQUIRED, CASE_CREATION, or CASE_QUERY")
            confidence: float = Field(description="0.0 to 1.0")
            reasoning: str = Field(description="Brief explanation")
        
        current_date_str = datetime.now().strftime("%A %d de %B de %Y")
        
        # Build context
        context_parts = []
        if has_files:
            context_parts.append("Usuario adjuntÃ³ archivos/documentos")
        if case_id:
            context_parts.append("Hay un caso activo en contexto")
        context_str = " | ".join(context_parts) if context_parts else "Sin contexto especial"
        
        prompt = f"""Clasifica la intenciÃ³n del siguiente mensaje en UNA de estas categorÃ­as:

FECHA ACTUAL: {current_date_str}
CONTEXTO: {context_str}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CATEGORÃAS (ordenadas por prioridad)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. **CASE_CREATION**: Usuario describe un incidente/denuncia laboral para documentar
   SeÃ±ales:
   - Describe una situaciÃ³n que ocurriÃ³ con trabajadores especÃ­ficos
   - Menciona conductas problemÃ¡ticas reales (acoso, violencia, conflicto, etc.)
   - Da detalles sobre involucrados, fechas, lugares
   
   âœ… Ejemplos SÃ CASE_CREATION:
   - "Tengo una denuncia por acoso laboral del jefe de bodega"
   - "Un trabajador agrediÃ³ verbalmente a su supervisor"
   - "Necesito registrar un caso de hostigamiento"
   
   âŒ NO es CASE_CREATION:
   - "Â¿QuÃ© es acoso laboral?" (pregunta genÃ©rica â†’ SIMPLE_QA)
   - "Â¿QuÃ© hacer si hay violencia?" (pregunta hipotÃ©tica â†’ SIMPLE_QA)

2. **DOCUMENT_ANALYSIS**: Usuario quiere buscar/analizar documentos ESPECÃFICOS
   SeÃ±ales:
   - Menciona un documento por nombre/nÃºmero ("Ley Karin", "Reglamento Interno", "contrato")
   - Pide buscar en archivos almacenados
   - Hace referencia a archivos adjuntos actualmente
   - Pregunta sobre contenido de documentos concretos
   
   âœ… Ejemplos SÃ DOCUMENT_ANALYSIS:
   - "Â¿QuÃ© dice el Reglamento Interno sobre sanciones?"
   - "Busca el protocolo de investigaciÃ³n"
   - "Â¿QuÃ© contiene la ley 21.643?"
   
   âŒ NO es DOCUMENT_ANALYSIS:
   - "Â¿QuÃ© es un protocolo de acoso?" (pregunta genÃ©rica â†’ SIMPLE_QA)
   - "Â¿CÃ³mo funciona la investigaciÃ³n?" (conocimiento general â†’ SIMPLE_QA)

3. **SIMPLE_QA**: Preguntas GENERALES sobre prevenciÃ³n y Ley Karin
   SeÃ±ales:
   - Pregunta conceptual o de conocimiento general
   - NO menciona documentos especÃ­ficos ni casos concretos
   - Busca entender procesos, definiciones, mejores prÃ¡cticas
   
   âœ… Ejemplos SÃ SIMPLE_QA:
   - "Â¿QuÃ© es acoso laboral?"
   - "Â¿CuÃ¡les son los plazos de investigaciÃ³n?"
   - "Diferencia entre conflicto y acoso"
   - "Â¿QuÃ© tipos de denuncias existen?"
   - "Â¿CÃ³mo se documenta un caso?" (pregunta de proceso)
   
   âŒ NO es SIMPLE_QA:
   - "Â¿QuÃ© dice MI reglamento sobre sanciones?" (pide documento especÃ­fico â†’ DOCUMENT_ANALYSIS)

4. **TOOL_REQUIRED**: PeticiÃ³n de herramientas externas (calendario/email)
   SeÃ±ales:
   - Quiere EJECUTAR una acciÃ³n (enviar, agendar, programar)
   - Menciona correo, email, reuniÃ³n, cita, citaciÃ³n
   
   âœ… Ejemplos SÃ TOOL_REQUIRED:
   - "EnvÃ­a una notificaciÃ³n al denunciado"
   - "Agenda una citaciÃ³n para declarar"
   
   âŒ NO es TOOL_REQUIRED:
   - "Â¿CÃ³mo redacto una notificaciÃ³n?" (pide instrucciones â†’ SIMPLE_QA)
   - "Â¿CuÃ¡ndo debo citar a declarar?" (pregunta â†’ SIMPLE_QA)

5. **CASE_QUERY**: Pregunta sobre un caso activo (SOLO si hay case_id activo)
   - "Â¿De quÃ© trata este caso?"
   - "Â¿QuiÃ©n estÃ¡ involucrado?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
REGLAS DE DESAMBIGUACIÃ“N
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”‘ CLAVE #1: Pregunta genÃ©rica vs documento especÃ­fico
- "Â¿QuÃ© es acoso laboral?" â†’ SIMPLE_QA (genÃ©rico)
- "Â¿QuÃ© dice MI REGLAMENTO sobre acoso?" â†’ DOCUMENT_ANALYSIS (especÃ­fico)

ğŸ”‘ CLAVE #2: Caso real vs pregunta hipotÃ©tica
- "El gerente de Ã¡rea hostigÃ³ a un trabajador ayer" â†’ CASE_CREATION (real)
- "Â¿QuÃ© hago si hay hostigamiento?" â†’ SIMPLE_QA (hipotÃ©tico)

ğŸ”‘ CLAVE #3: Ejecutar acciÃ³n vs pedir instrucciones
- "Redacta una citaciÃ³n al denunciado" â†’ TOOL_REQUIRED (ejecutar)
- "Â¿CÃ³mo redacto una citaciÃ³n formal?" â†’ SIMPLE_QA (instrucciones)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MENSAJE A CLASIFICAR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"{message}"

Responde con JSON vÃ¡lido: {{"intent": "CATEGORIA", "confidence": 0.0-1.0, "reasoning": "explicaciÃ³n breve"}}"""

        try:
            # Single LLM call with JSON response
            messages = [HumanMessage(content=prompt)]
            raw_response = await self.llm.ainvoke(messages)
            
            # Track usage
            if user_id and hasattr(raw_response, 'usage_metadata'):
                usage = raw_response.usage_metadata
                if usage:
                    user_service.update_token_usage(
                        user_id=user_id,
                        input_tokens=usage.get('input_tokens', 0),
                        output_tokens=usage.get('output_tokens', 0),
                        model_name=self.llm.model_name
                    )
            
            # Parse JSON response
            import json
            import re
            content = raw_response.content
            
            # Extract JSON from markdown if present
            if "```json" in content:
                content = re.search(r'```json\s*([\s\S]*?)\s*```', content).group(1)
            elif "```" in content:
                content = content.split("```")[1]
            
            data = json.loads(content)
            result = IntentClassification(**data)
            
            logger.info(f"ğŸ¯ [INTENT] {result.intent} (conf: {result.confidence:.2f})")
            
            return {
                "intent": result.intent,
                "confidence": result.confidence,
                "reasoning": result.reasoning
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ [INTENT] Classification error: {e}")
            return {
                "intent": self.SIMPLE_QA,
                "confidence": 0.5,
                "reasoning": f"Error: {str(e)[:30]}"
            }


# Singleton instance
intent_router = IntentRouter()
